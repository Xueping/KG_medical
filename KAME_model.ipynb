{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "from src.GRAM.gram_helpers import calculate_dimSize, get_rootCode, build_tree\n",
    "from src.KAME.kame_helpers import codes2ancestors, leaf2ancestors, load_data, pad_matrix\n",
    "from src.KAME.kame_module import KAME as model\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_file = 'outputs/mimic'\n",
    "seq_file = 'outputs/mimic.seqs'\n",
    "label_file = 'outputs/mimic.3digitICD9.seqs'\n",
    "\n",
    "embd_dim_size = 100\n",
    "attn_dim_size = 100\n",
    "rnn_dim_size = 100\n",
    "g_dim_size = 100\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDimSize = calculate_dimSize(seq_file)\n",
    "numClass = calculate_dimSize(label_file)\n",
    "numAncestors = get_rootCode(tree_file+'.level2.pk') - inputDimSize + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4894, 668, 942)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDimSize,numAncestors, numClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves_list = []\n",
    "ancestors_list = []\n",
    "for i in range(5, 0, -1):\n",
    "    leaves, ancestors = build_tree(tree_file + '.level' + str(i) + '.pk')\n",
    "    leaves_list.extend(leaves)\n",
    "    ancestors_list.extend(ancestors)\n",
    "            \n",
    "seqs = pickle.load(open(seq_file, 'rb'))\n",
    "labels = pickle.load(open(label_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_list = []\n",
    "internal_ancestors_list = []\n",
    "\n",
    "for i in range(4, 0, -1):\n",
    "    leaves, ancestors = build_tree(tree_file + '.a_level' + str(i) + '.pk')\n",
    "    internal_list.extend(leaves)\n",
    "    internal_ancestors_list.extend(ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(leaves_list, ancestors_list, internal_list, internal_ancestors_list, inputDimSize, numAncestors, \n",
    "         embd_dim_size, attn_dim_size, rnn_dim_size, g_dim_size, numClass, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KAME(\n",
       "  (linear): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc): Linear(in_features=200, out_features=942, bias=True)\n",
       "  (embed_init): Embedding(5562, 100)\n",
       "  (dag_attention): DAGAttention(\n",
       "    (linear1): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (linear2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       "  (gru): GRU(100, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (embed_a): Embedding(669, 100)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf2ans = leaf2ancestors(tree_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ... \n",
      "done!!\n"
     ]
    }
   ],
   "source": [
    "print('Loading data ... ')\n",
    "train_set, valid_set, test_set = load_data(seqs, labels, leaf2ans, inputDimSize)\n",
    "\n",
    "data_dict = dict()\n",
    "data_dict['train'] = train_set\n",
    "data_dict['val'] = valid_set\n",
    "data_dict['test'] = test_set\n",
    "print('done!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 4894) (100, 1, 73) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 72) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 73) (100, 1, 942)\n",
      "(100, 3, 4894) (100, 3, 69) (100, 3, 942)\n",
      "(100, 1, 4894) (100, 1, 80) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 76) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 73) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 73) (100, 1, 942)\n",
      "(100, 2, 4894) (100, 2, 81) (100, 2, 942)\n",
      "(100, 1, 4894) (100, 1, 68) (100, 1, 942)\n",
      "(100, 5, 4894) (100, 5, 80) (100, 5, 942)\n",
      "(100, 1, 4894) (100, 1, 77) (100, 1, 942)\n",
      "(100, 3, 4894) (100, 3, 80) (100, 3, 942)\n",
      "(100, 1, 4894) (100, 1, 80) (100, 1, 942)\n",
      "(77, 33, 4894) (77, 33, 71) (77, 33, 942)\n",
      "(100, 1, 4894) (100, 1, 74) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 65) (100, 1, 942)\n",
      "(100, 3, 4894) (100, 3, 65) (100, 3, 942)\n",
      "(100, 1, 4894) (100, 1, 78) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 77) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 68) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 80) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 69) (100, 1, 942)\n",
      "(100, 7, 4894) (100, 7, 76) (100, 7, 942)\n",
      "(100, 1, 4894) (100, 1, 80) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 69) (100, 1, 942)\n",
      "(100, 3, 4894) (100, 3, 71) (100, 3, 942)\n",
      "(100, 1, 4894) (100, 1, 76) (100, 1, 942)\n",
      "(100, 2, 4894) (100, 2, 79) (100, 2, 942)\n",
      "(100, 1, 4894) (100, 1, 83) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 68) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 82) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 71) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 78) (100, 1, 942)\n",
      "(100, 2, 4894) (100, 2, 63) (100, 2, 942)\n",
      "(100, 1, 4894) (100, 1, 69) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 73) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 76) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 72) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 74) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 72) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 78) (100, 1, 942)\n",
      "(100, 2, 4894) (100, 2, 84) (100, 2, 942)\n",
      "(100, 4, 4894) (100, 4, 68) (100, 4, 942)\n",
      "(100, 1, 4894) (100, 1, 75) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 66) (100, 1, 942)\n",
      "(100, 1, 4894) (100, 1, 75) (100, 1, 942)\n",
      "(100, 2, 4894) (100, 2, 65) (100, 2, 942)\n",
      "(100, 2, 4894) (100, 2, 61) (100, 2, 942)\n",
      "(100, 2, 4894) (100, 2, 77) (100, 2, 942)\n",
      "(100, 1, 4894) (100, 1, 78) (100, 1, 942)\n",
      "(100, 2, 4894) (100, 2, 76) (100, 2, 942)\n",
      "(100, 2, 4894) (100, 2, 70) (100, 2, 942)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "batch_size = 100\n",
    "data_set = data_dict['train']\n",
    "n_batches = int(np.ceil(float(len(data_set[0])) / float(batch_size)))\n",
    "\n",
    "# Iterate over data.\n",
    "for index in random.sample(range(n_batches), n_batches):\n",
    "    batchX = data_set[0][index * batch_size:(index + 1) * batch_size]\n",
    "    batchF = data_set[1][index * batch_size:(index + 1) * batch_size]\n",
    "    batchY = data_set[2][index * batch_size:(index + 1) * batch_size]\n",
    "    x, f, y, mask, lengths = pad_matrix(batchX, batchF, batchY, inputDimSize, numAncestors, numClass)\n",
    "    print(x.shape, f.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[227, 231, 236, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[236, 240, 241, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[105, 106, 241, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[103, 105, 107, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[227, 358, 231, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]],\n",
       "\n",
       "       [[548, 549, 553, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = torch.from_numpy(x).to(device)\n",
    "batch_f = torch.from_numpy(f).to(device)\n",
    "batch_y = torch.from_numpy(y).to(device)\n",
    "# lengths = torch.from_numpy(lengths).to(device)\n",
    "output = model(batch_x, batch_f, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 2, 942]), (100, 2, 70), torch.Size([100, 2, 70]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, f.shape, batch_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embed_a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = out.size()\n",
    "out_re = out.reshape(size[0], size[1],1,size[2])\n",
    "hl = (out_re * l).sum(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ans = (batch_f > 0)\n",
    "\n",
    "VERY_NEGATIVE_NUMBER = -1e30\n",
    "mask_rank = (1-mask_ans.double()) * VERY_NEGATIVE_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl += mask_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.softmax(hl, dim=-1)\n",
    "x2 = weights.unsqueeze(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = (x2*l).sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.cat([out,k], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
